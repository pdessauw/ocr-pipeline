{"name":"Ocr-pipeline","tagline":"Convert a corpus of PDF to clean text files on a distributed architecture","body":"# OCR Pipeline \r\n\r\n**Author:** Philippe Dessauw, philippe.dessauw@nist.gov\r\n\r\n**Contact:** Alden Dima, alden.dima@nist.gov\r\n\r\n[![Scrutinizer Code Quality](https://scrutinizer-ci.com/g/usnistgov/ocr-pipeline/badges/quality-score.png?b=master)](https://scrutinizer-ci.com/g/usnistgov/ocr-pipeline/?branch=master)\r\n\r\n-----\r\n\r\n## Description\r\n\r\nThe **OCR Pipeline** (referred later as the \"pipeline\") is designed to convert PDF files to clean TXT files in 3 steps:\r\n\r\n1. PDF to PNG conversion with *PythonMagick* (Python binding for ImageMagick),\r\n2. PNG to TXT conversion using *Ocropy*,\r\n3. TXT cleaning in order to remove all trace of garbage strings.\r\n\r\nThe pipeline is running on a distributed master/slave architecture with a *Redis* queue as a communication layer.\r\n\r\n* One master server is reading input content to build the job queue,\r\n* Slaves pop jobs from that queue and process them.\r\n\r\nThe software is developed by the National Institute of Standards and Technology (NIST).\r\n\r\n*N.B.:* This software has exclusively been designed to be run on **Linux servers**. Execution on Mac and Windows has not \r\nbeen tested.\r\n\r\n\r\n## Prerequisites\r\n\r\n### Python\r\n\r\nThe pipeline is developed in *Python2* (>=2.7). You can check your version using:\r\n\r\n\t$> python2 --version\r\n\r\n**Warning:** The pipeline is not designed to work in Python3. Make sure your path point towards a Python2 installation.\r\n\r\n#### Virtual environment\r\n\r\nWe recommend using a Python virtual environment to ensure proper operation of the pipeline. Make sure your environment \r\nis activated at installation time.\r\n\r\n#### Packages\r\n\r\nThere are two package that needed to be installed before installing the pipeline: **pip** and **PythonMagick**.\r\n\r\n##### pip\r\n\r\nThis package will be used to install the packages bundled in this repository and their dependancies. No manual action is \r\nrequired to install dependancies.\r\n\r\n##### PythonMagick\r\n\r\nThis package needs to be manually installed. Its version is heavily dependent on your **ImageMagick** version. Please \r\nvisit http://www.imagemagick.org for more information.\r\n\r\n### Redis\r\n\r\nRedis needs to be installed on the master server. Redis version should be **>= 2.7**. Follow Redis installation steps at \r\nhttp://redis.io/download#installation.\r\n\r\n### Ocropy\r\n\r\nOcropy is required to convert images to text files. The code is available at https://github.com/tmbdev/ocropy. Make sure \r\nit is downloaded and can be launched on all your slaves.\r\n\r\n### XServer\r\n\r\nThe command `xvfb-run` should be available for our scripts. Depending on your operating system, it is not always stored \r\nin the same package. Please refer to your OS package manager to download it.\r\n\r\n### NLTK\r\n\r\nIn order for NLTK to run properly, you need to download the **english tokenizer**. The following python code will check \r\nyour NLTK installation and get the tokenizer if it is not present:\r\n\r\n\timport nltk\r\n\t\r\n\ttry:\r\n\t    nltk.data.find('tokenizers/punkt')\r\n\texcept:\r\n\t    nltk.download('punkt')\r\n\r\n\r\n## Downloading the project\r\n\r\nOnce all the prerequisites are met, download the project:\r\n\r\n1. Get the source code on Github:\r\n\t\r\n\t\t$> cd /path/to/workspace\r\n\t\t$> git clone https://github.com/usnistgov/ocr-pipeline.git\r\n\r\n2. Configure the application:\r\n\r\n\t\t$> cd ocr-pipeline\r\n\t\t$> cp -r conf.sample conf\r\n\r\n\r\n## Configuration\r\n\r\nAll the configuration should be put in the *conf* folder.\r\n\r\n### app.yaml\r\n\r\n#### root\r\n\r\nAbsolute path to the pipeline code. The project will be copied to this location when you install and run the pipeline.\r\n\r\n#### use_sudo\r\n\r\nDefine if the script needs to use sudo to install the pipeline.\r\n\r\n#### commands / list # PNGReader / ocropy / location\r\n\r\nPath where you have downloaded Ocropy.\r\n\r\n#### commands / list # PNGReader / ocropy / model\r\n\r\nPath where you have downloaded the Ocropy model (*en-default.pyrnn.gz*).\r\n\r\n### env.yaml\r\n\r\n#### python / path\r\n\r\nPath of your general Python installation.\r\n\r\n#### python / virtualenv\r\n\r\nPath of your virtual environment. Comment this line if not needed.\r\n\r\n### machines.yaml\r\n\r\n#### master\r\n\r\nThe IP address of the master is in the form of a connection string. It is formatted as a list but only the first element \r\nis relevant.\r\n\r\n#### slaves\r\n\r\nList of connection strings to the slaves.\r\n\r\n\r\n## Installation\r\n\r\nHere are the steps you have to follow to install the pipeline on your architecture machine.\r\n\r\n1. Initialize the application on your first machine\r\n\t\r\n\t\t$> cd /path/to/ocr-pipeline\r\n\t\t$> ./utils/install.sh\r\n\t\t$> ./ui.sh init\r\n\r\n2. Create data models\r\n\r\n\t\t$> ./ui.sh create_models /path/to/training_set\r\n\r\n*N.B.* : Depending on your training set, this step could take some time to complete.\r\n\r\n3. Install the pipeline on slaves and master\r\n\t\r\n\t\t$> ./ui.sh -r install\r\n\r\n4. Check that everything is installed on all the machines\r\n\r\n\t\t$> ./ui.sh -r check\r\n\r\n\r\n## Running the pipeline\r\n\r\n### Incoming data\r\n\r\nWhen you want to start converting a corpus of PDF files, you have to place the files in the input directory. By default, \r\nthis directory is named *data.in*.\r\n\r\n### Starting the pipeline\r\n\r\nTo start the pipeline, you just have to run `./ui.sh -r start_pipeline`. It will remotely start all the slaves and the \r\nmaster. \r\n\r\n### Output\r\n\r\nEach time a new file has been processed, it will be put in the output directory of the master server. By default, this \r\ndirectory is named *data.out*.\r\n\r\n## Contact\r\n\r\nIf you encouter any issue or bug with this software please use the [issue tracker](https://github.com/usnistgov/ocr-pipeline/issues). \r\nIf you want to make some enhancement, feel free to fork this repository and submit a pull request once your new feature \r\nis ready.\r\n\r\nIf you have any questions, comments or suggestions about this repository, please send an e-mail to Alden Dima \r\n(alden.dima@nist.gov).\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}